import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import skew
from scipy.signal import detrend
from statsmodels.tsa.stattools import adfuller
import statsmodels.api as sm
import statsmodels.formula.api as smf
from statsmodels.stats.outliers_influence import variance_inflation_factor
import patsy
from scipy.stats import f
from scipy import stats
from statsmodels.stats.diagnostic import het_breuschpagan

# Omzetten naar long format
df = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\COUNT - Poging 1\\VAR_ipo_count_per_country_per_year.xlsx')

df_long = df.melt(id_vars="country", var_name="year", value_name="ipo_count")

df_long.to_excel("ipo_long_format.xlsx", index=False)




# Door met daadwerkelijke bestand
data = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\COUNT - Poging 1\\data.xlsx')


#Drop 2025 from observations
data = data[data['year'] != 2025]



# MVS variabele toepassen (Frankrijk wet gaat pas vanaf 2025 in; Duitsland heb ik gepakt zijnde vanaf 2024, zie artikel 35 van die wet)
always_allowed = [
    'Cyprus', 'Denmark', 'Finland', 'Hungary', 'Ireland', 'Malta',
    'Netherlands', 'Portugal', 'Czech Republic', 'Sweden'
]

data['mvs_allowed'] = 0
data.loc[data['country'].isin(always_allowed), 'mvs_allowed'] = 1
data.loc[(data['country'] == 'Italy') & (data['year'] >= 2015), 'mvs_allowed'] = 1
data.loc[(data['country'] == 'Germany') & (data['year'] >= 2024), 'mvs_allowed'] = 1


# Governance indicators dropping and merging
wgi = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\Onafhankelijke variabelen\\Governance.xlsx')
wgi_wide = wgi.pivot_table(index=['countryname', 'year'],
                           columns='indicator',
                           values='index').reset_index()
wgi_wide = wgi_wide.drop(columns=['va', 'pv'])
data = data.merge(wgi_wide, left_on=['country', 'year'], right_on=['countryname', 'year'], how='left')
data = data.drop(columns=['countryname'])


# Averaging 1997, 1999 and 2001
gov_cols = ['cc', 'ge', 'rl', 'rq']
for col in gov_cols:
    for year in [1997, 1999, 2001]:
        mask = (data['year'] == year) & (data[col].isna())
        idxs = data[mask].index
        for idx in idxs:
            ctry = data.loc[idx, 'country']
            val_before = data.loc[(data['country'] == ctry) & (data['year'] == year - 1), col]
            val_after = data.loc[(data['country'] == ctry) & (data['year'] == year + 1), col]
            if not val_before.empty and not val_after.empty:
                avg = (val_before.values[0] + val_after.values[0]) / 2
                data.at[idx, col] = avg

# One year lag for IPO count
data = data.sort_values(by=['country', 'year'])
data['ipo_count_lag'] = data.groupby('country')['ipos'].shift(1)


# Drop the 1995 and 2024 data (no observations for governance).
data = data[(data['year'] >= 2009) & (data['year'] <= 2019)]


# Year dummy variables toepassen
conditions = [
    (data['year'] >= 2009) & (data['year'] <= 2012),
    (data['year'] >= 2013) & (data['year'] <= 2015),
    (data['year'] >= 2016) & (data['year'] <= 2019),
]

labels = ['2009_2012', '2013_2015', '2016_2019']
data['period'] = np.select(conditions, labels, default='other')
period_dummies = pd.get_dummies(data['period'], prefix='period')
data = pd.concat([data, period_dummies], axis=1)

# GOVERNANCE - ACTION 1: Detrend ALL governance indices
df = data.reset_index()
gov_vars = ['cc', 'ge', 'rl', 'rq']
for var in gov_vars:
    df[f'{var}_detrended'] = df[var]
    for country in df['country'].unique():
        df_country = df[df['country'] == country]
        if len(df_country) > 5:
            detrended_values = detrend(df_country[var].values, type='linear')
            df.loc[df_country.index, f'{var}_detrended'] = detrended_values

data = df.set_index(['country', 'year'])
data = data.reset_index()

# Adding last-year PE data
PE = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\Onafhankelijke variabelen\\PE\\PE_ratio_yearly.xlsx')
data = data.merge(PE[['year', 'PE_lag']], on='year', how='left')

# Adding last-year investor sentiment data
underpricing = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\Onafhankelijke variabelen\\Underpricing\\final_underpricing.xlsx')
underpricing = underpricing.sort_values('year')
underpricing['avg_underpricing_total_lag'] = underpricing['avg_underpricing_total'].shift(1)
underpricing = underpricing[underpricing['year'] != 1995]
data = data.merge(underpricing[['year', 'avg_underpricing_total_lag']], on='year', how='left')

# Adding logtransformed GDP data
gdp = pd.read_excel('D:\\Erasmus Universiteit\\Jaar 5\\Blok 5\\Scriptie OR\\DATA\\Hoofdstuk 3\\Deel 4 - Onderzoek\\Onafhankelijke variabelen\\GDP data.xlsx')
gdp = gdp.replace(",", ".", regex=True)
gdp.iloc[:, 1:] = gdp.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')
gdp = gdp.melt(id_vars=gdp.columns[0], var_name='year', value_name='gdp')
gdp.columns = ['country', 'year', 'gdp']
gdp['year'] = gdp['year'].astype(int)
data = data.merge(gdp, on=["country", "year"], how="left")
data['log_gdp'] = np.log(data['gdp'])



# Regression
formula = (
    "ipos ~ mvs_allowed"
    + " + period_2013_2015 + period_2016_2019"
    + " + ipo_count_lag + log_gdp"
    + " + cc_detrended + ge_detrended + rl_detrended + rq_detrended"
    + " + avg_underpricing_total_lag + PE_lag"
)


model = smf.ols(formula=formula, data=data).fit(
    cov_type='cluster',
    cov_kwds={'groups': data['country']}
)

print(model.summary())

print("Mean of residuals:", model.resid.mean())

results_df = pd.DataFrame({
    'coef': model.params,
    'std_err': model.bse,
    't': model.tvalues,
    'p_value': model.pvalues
})

results_df.to_excel("regression_count_results.xlsx", index=True)

# Breusch-Pagan for homoscedasticity
residuals = model.resid
exog = model.model.exo
bp_test = het_breuschpagan(residuals, exog)
bp_stat, bp_pval, f_stat, f_pval = bp_test
print(f"Breusch-Pagan test statistic: {bp_stat:.4f}")
print(f"p-value: {bp_pval:.4f}")


# Normality test - VIF
variables = [
    'mvs_allowed', 'ipo_count_lag', 'period_2013_2015', 'period_2016_2019',
    'cc_detrended', 'ge_detrended', 'rl_detrended', 'rq_detrended',
    'PE_lag', 'avg_underpricing_total_lag'
]
X = data[variables].apply(pd.to_numeric, errors='coerce').dropna()
bool_cols = ['period_2013_2015', 'period_2016_2019']
X[bool_cols] = X[bool_cols].astype(int)
X = add_constant(X)
vif_data = pd.DataFrame()
vif_data["Variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
vif_data.to_excel("vif_scores_count.xlsx", index=False)
print(vif_data)




# Normality tests - non-stationarity

# COUNT - TEST 1: visualizing
df_yearly = data.reset_index()
avg_by_year = df_yearly.groupby('year')[['ipos']].mean()
plt.figure(figsize=(12, 6))
for col in avg_by_year.columns:
    plt.plot(avg_by_year.index, avg_by_year[col], label=col)
plt.title("Average Count Over Time (All Countries)")
plt.xlabel("Year")
plt.ylabel("Average Value")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# COUNT - TEST 2: - regression of time to detect trend.
df_reset = data.reset_index()
trend_results = []

for country in df_reset['country'].unique():
    df_country = df_reset[df_reset['country'] == country].dropna(subset=['ipos', 'year'])
    if len(df_country) > 5:
        X = sm.add_constant(df_country['year'])
        y = df_country['ipos']
        model = sm.OLS(y, X).fit()
        trend_results.append({
            'country': country,
            'intercept': model.params['const'],
            'trend_coef': model.params['year'],
            'p_value_trend': model.pvalues['year'],
            'n_obs': int(model.nobs),
            'r_squared': model.rsquared,
            'trend_significant_5pct': model.pvalues['year'] < 0.05
        })

trend_df = pd.DataFrame(trend_results)
trend_df.to_excel('country_count_trend_results.xlsx', index=False)


# COUNT - TEST 3: regression of time, general level
df_clean = df_reset.dropna(subset=['ipos', 'year'])
X = sm.add_constant(df_clean['year'])
y = df_clean['ipos']
model = sm.OLS(y, X).fit()
print(model.summary())


# COUNT - TEST 4: per land testen om non-stationarity (ADF 2)
df = data.reset_index()
results = []
for country in df['country'].unique():
    series = df[df['country'] == country]['ipos'].dropna()
    if len(series) > 5:
        result = adfuller(series, regression='c', autolag='AIC')
        results.append({
            'country': country,
            'ADF_statistic': result[0],
            'p_value': result[1],
            'n_obs': result[3],
            'critical_1%': result[4]['1%'],
            'critical_5%': result[4]['5%'],
            'critical_10%': result[4]['10%'],
            'stationary_at_5pct': result[1] < 0.05
        })

adf_per_country_df = pd.DataFrame(results)
adf_per_country_df.to_excel("adf_test2_ipo_count_per_country.xlsx", index=False)

# COUNT - TEST 5: pooled testen op non-stationarity (ADF 2)
ipo_series_all = data['ipos'].dropna()
result = adfuller(ipo_series_all, regression='c', autolag='AIC')

adf_summary = {
    'ADF_statistic': result[0],
    'p_value': result[1],
    'n_obs': result[3],
    'critical_1%': result[4]['1%'],
    'critical_5%': result[4]['5%'],
    'critical_10%': result[4]['10%'],
    'stationary_at_5pct': result[1] < 0.05
}

adf_df = pd.DataFrame([adf_summary])
adf_df.to_excel("adf_test2_pooled_ipo_count.xlsx", index=False)




# GOVERNANCE - TEST 1: Trend test per country
gov_vars = ['cc', 'ge', 'rl', 'rq']
df_reset = data.reset_index()
trend_results = []

for var in gov_vars:
    for country in df_reset['country'].unique():
        df_country = df_reset[df_reset['country'] == country].dropna(subset=[var, 'year'])      
        if len(df_country) > 5:
            X = sm.add_constant(df_country['year'])
            y = df_country[var]
            model = sm.OLS(y, X).fit()
            trend_results.append({
                'variable': var,
                'country': country,
                'trend_coef': model.params['year'],
                'p_value_trend': model.pvalues['year'],
                'trend_significant_5pct': model.pvalues['year'] < 0.05,
                'n_obs': int(model.nobs),
                'r_squared': model.rsquared
            })

trend_df = pd.DataFrame(trend_results)
trend_df.to_excel("governance_trend_test_by_country.xlsx", index=False)

# GOVERNANCE - TEST 2: Trend test overall
gov_vars = ['cc', 'ge', 'rl', 'rq']
trend_results = []

for var in gov_vars:
    df_var = data.dropna(subset=[var, 'year'])
    X = sm.add_constant(df_var['year'])
    y = df_var[var]
    model = sm.OLS(y, X).fit()
    trend_results.append({
        'variable': var,
        'trend_coef': model.params['year'],
        'p_value_trend': model.pvalues['year'],
        'trend_significant_5pct': model.pvalues['year'] < 0.05,
        'n_obs': int(model.nobs),
        'r_squared': model.rsquared
    })

trend_df = pd.DataFrame(trend_results)
trend_df.to_excel("governance_trend_overall.xlsx", index=False)

# GOVERNANCE - TEST 3: Non-stationarity test on detrended vars
gov_vars = ['cc_detrended', 'ge_detrended', 'rl_detrended', 'rq_detrended']

df1_results = []
for var in gov_vars:
    series = data[var].dropna()
    result = adfuller(series, regression='n', autolag='AIC')
    df1_results.append({
        'variable': var,
        'ADF_statistic': result[0],
        'p_value': result[1],
        'n_obs': result[3],
        'critical_1%': result[4]['1%'],
        'critical_5%': result[4]['5%'],
        'critical_10%': result[4]['10%'],
        'stationary_at_5pct': result[1] < 0.05
    })

df1_df = pd.DataFrame(df1_results)
df1_df.to_excel("adf_test1_detrended_governance.xlsx", index=False)

# GOVERNANCE - TEST 4: Non-stationarity test on detrended vars per country
gov_vars = ['cc_detrended', 'ge_detrended', 'rl_detrended', 'rq_detrended']
df_reset = data.reset_index()
adf_results = []

for var in gov_vars:
    for country in df_reset['country'].unique():
        series = df_reset.loc[df_reset['country'] == country, var].dropna()
        if len(series) > 5:
            result = adfuller(series, regression='n', autolag='AIC')
            adf_results.append({
                'variable': var,
                'country': country,
                'ADF_statistic': result[0],
                'p_value': result[1],
                'n_obs': result[3],
                'critical_1%': result[4]['1%'],
                'critical_5%': result[4]['5%'],
                'critical_10%': result[4]['10%'],
                'stationary_at_5pct': result[1] < 0.05
            })

adf_df = pd.DataFrame(adf_results)
adf_df.to_excel("adf_test_by_country_detrended_governance.xlsx", index=False)










# List of skewness within variables to Excel
vars_to_skew = ['ipos', 'cc_detrended', 'ge_detrended', 'rl_detrended', 'rq_detrended', 'ipo_count_lag', 'period_2009_2012', 'period_2013_2015','period_2016_2019', 'PE_lag', 'avg_underpricing_total_lag']
skew_dict = {}

for var in vars_to_skew:
    skew_dict[var] = data.groupby('country')[var].apply(skew)

skew_df = pd.DataFrame(skew_dict).reset_index()
skew_df.to_excel("skewness_selected_variables_by_country.xlsx", index=False)

# Calculate skewness aggregated level
vars_to_check = [
    'ipos', 'cc_detrended', 'ge_detrended', 'rl_detrended', 'rq_detrended',
    'ipo_count_lag', 'period_2009_2012', 'period_2013_2015', 'period_2016_2019',
    'PE_lag', 'avg_underpricing_total_lag'
]
skew_results = []
for var in vars_to_check:
    clean_series = data[var].dropna()
    skew_val = skew(clean_series)
    skew_results.append({
        'variable': var,
        'skewness': skew_val,
        'n_obs': len(clean_series)
    })

skew_data = pd.DataFrame(skew_results)
skew_data.to_excel("skewness_results.xlsx", index=False)